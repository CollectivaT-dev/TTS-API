version: '3.7'

services:

  tts:
    build: .
    command: gunicorn server:app -b :8000 --workers 4 --timeout 300 --worker-class=gthread 
    restart: unless-stopped
    ports:
      - 5050:8000
    volumes:
      - .:/app
    container_name: ttsapi
    environment:
      - TTS_API_CONFIG=/app/config.json
      - MODELS_ROOT=/app/models
      - USE_CUDA=0  #1 to enable GPU inference
    #Remove comment below to enable GPU inference
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1 #set to "all" to use all GPUs
    #           capabilities: [gpu]
    #Remove comment above to enable GPU inference
